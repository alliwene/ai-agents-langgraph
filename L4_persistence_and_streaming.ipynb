{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence and Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AnyMessage,\n",
    "    BaseMessage,\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BaseChatModel,\n",
    "        tools: Sequence[BaseTool],\n",
    "        checkpointer: BaseCheckpointSaver,\n",
    "        system: str = \"\",\n",
    "    ) -> None:\n",
    "        self.system = system\n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_llm)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\", self.exists_action, {True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState) -> bool:\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def call_llm(self, state: AgentState) -> dict[str, list[BaseMessage]]:\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState) -> dict[str, list[ToolMessage]]:\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results: list[ToolMessage] = []\n",
    "\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if t[\"name\"] not in self.tools:\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"\n",
    "            else:\n",
    "                result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(\n",
    "                ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result))\n",
    "            )\n",
    "        print(\"Back to the model!\")\n",
    "        \n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
    "# model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in Ibadan?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_n6c6', 'function': {'arguments': '{\"query\":\"current weather in Ibadan\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 1016, 'total_tokens': 1067, 'completion_time': 0.143144354, 'prompt_time': 0.195837961, 'queue_time': None, 'total_time': 0.338982315}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6b690b75-f24b-42e3-8470-13997875d294-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Ibadan'}, 'id': 'call_n6c6'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Ibadan'}, 'id': 'call_n6c6'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Ibadan\\', \\'region\\': \\'Oyo\\', \\'country\\': \\'Nigeria\\', \\'lat\\': 7.39, \\'lon\\': 3.9, \\'tz_id\\': \\'Africa/Lagos\\', \\'localtime_epoch\\': 1718203238, \\'localtime\\': \\'2024-06-12 15:40\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718202600, \\'last_updated\\': \\'2024-06-12 15:30\\', \\'temp_c\\': 29.1, \\'temp_f\\': 84.5, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Patchy rain nearby\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/176.png\\', \\'code\\': 1063}, \\'wind_mph\\': 3.4, \\'wind_kph\\': 5.4, \\'wind_degree\\': 179, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1011.0, \\'pressure_in\\': 29.85, \\'precip_mm\\': 1.01, \\'precip_in\\': 0.04, \\'humidity\\': 71, \\'cloud\\': 77, \\'feelslike_c\\': 33.2, \\'feelslike_f\\': 91.8, \\'windchill_c\\': 29.2, \\'windchill_f\\': 84.5, \\'heatindex_c\\': 33.2, \\'heatindex_f\\': 91.8, \\'dewpoint_c\\': 23.2, \\'dewpoint_f\\': 73.8, \\'vis_km\\': 9.0, \\'vis_miles\\': 5.0, \\'uv\\': 6.0, \\'gust_mph\\': 4.9, \\'gust_kph\\': 8.0}}\"}, {\\'url\\': \\'https://www.bbc.com/weather/2339354\\', \\'content\\': \\'14-day weather forecast for Ibadan.\\'}]', name='tavily_search_results_json', tool_call_id='call_n6c6')]\n",
      "[AIMessage(content='The current weather in Ibadan is 29.1°C (84.5°F) with patchy rain nearby.', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1524, 'total_tokens': 1549, 'completion_time': 0.068797524, 'prompt_time': 0.243723432, 'queue_time': None, 'total_time': 0.31252095599999996}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_e897b1804a', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd44b230-4056-4290-8bbc-7c49a47bb8e8-0')]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mw4r', 'function': {'arguments': '{\"query\":\"current weather in Calabar\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 1565, 'total_tokens': 1609, 'completion_time': 0.122601691, 'prompt_time': 0.290534298, 'queue_time': None, 'total_time': 0.41313598900000004}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_e897b1804a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8ec6e93e-9810-492a-b3d1-ee2556c7374e-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Calabar'}, 'id': 'call_mw4r'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Calabar'}, 'id': 'call_mw4r'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Calabar\\', \\'region\\': \\'Cross River\\', \\'country\\': \\'Nigeria\\', \\'lat\\': 4.95, \\'lon\\': 8.32, \\'tz_id\\': \\'Africa/Lagos\\', \\'localtime_epoch\\': 1718203298, \\'localtime\\': \\'2024-06-12 15:41\\'}, \\'current\\': {\\'last_updated_epoch\\': 1718202600, \\'last_updated\\': \\'2024-06-12 15:30\\', \\'temp_c\\': 29.1, \\'temp_f\\': 84.4, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Light rain shower\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/353.png\\', \\'code\\': 1240}, \\'wind_mph\\': 2.2, \\'wind_kph\\': 3.6, \\'wind_degree\\': 189, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 1010.0, \\'pressure_in\\': 29.83, \\'precip_mm\\': 1.41, \\'precip_in\\': 0.06, \\'humidity\\': 75, \\'cloud\\': 73, \\'feelslike_c\\': 34.0, \\'feelslike_f\\': 93.2, \\'windchill_c\\': 29.1, \\'windchill_f\\': 84.4, \\'heatindex_c\\': 34.0, \\'heatindex_f\\': 93.2, \\'dewpoint_c\\': 24.3, \\'dewpoint_f\\': 75.7, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 6.0, \\'gust_mph\\': 3.3, \\'gust_kph\\': 5.3}}\"}, {\\'url\\': \\'https://www.wunderground.com/hourly/ng/calabar-municipal/date/2022-10-18\\', \\'content\\': \\'Scattered thunderstorms during the evening. Cloudy skies after midnight. Low 72F. Winds light and variable. Chance of rain 60%. icon. Tomorrow 06/12.\\'}]', name='tavily_search_results_json', tool_call_id='call_mw4r')]}\n",
      "{'messages': [AIMessage(content='The current weather in Calabar is 29.1°C (84.4°F) with light rain showers.', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 2112, 'total_tokens': 2135, 'completion_time': 0.064158144, 'prompt_time': 0.353863231, 'queue_time': None, 'total_time': 0.41802137500000003}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_e897b1804a', 'finish_reason': 'stop', 'logprobs': None}, id='run-c1baa2eb-21c6-46ec-b1ff-9a2e80d728ea-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in Calabar?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Both Ibadan and Calabar have the same temperature, 29.1°C (84.4°F), so they are equally warm.', response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 2150, 'total_tokens': 2179, 'completion_time': 0.080462717, 'prompt_time': 0.357691134, 'queue_time': None, 'total_time': 0.43815385100000004}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-9587c3fa-5734-41e1-b66b-267ef456e77f-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different thread id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3vwy', 'function': {'arguments': '{\"query\":\"temperature comparison\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 1012, 'total_tokens': 1049, 'completion_time': 0.103642326, 'prompt_time': 0.16940547, 'queue_time': None, 'total_time': 0.273047796}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3cc6703c-0935-49d2-94b6-c41aeef27f0c-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison'}, 'id': 'call_3vwy'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison'}, 'id': 'call_3vwy'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://weatherandclimate.com/compare-climate', 'content': 'Compare Weather & Climate. Compare city weather on over a dozen categories such as: monthly weather averages, humidity, UV Index, snow, wind and air quality. 1st Location.'}, {'url': 'https://weatherspark.com/compare', 'content': 'Weather Spark lets you compare and contrast the weather and climate between any two to four cities worldwide. You get a detailed report with graphs showing the precise differences between them. Even better than a side-by-side comparison, the report shows you the information in unified graphs.'}]\", name='tavily_search_results_json', tool_call_id='call_3vwy')]}\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bs7q', 'function': {'arguments': '{\"query\":\"temperature comparison between two cities\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 1208, 'total_tokens': 1252, 'completion_time': 0.123637954, 'prompt_time': 0.218245176, 'queue_time': None, 'total_time': 0.34188313000000004}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-05ce95be-10f6-4127-af54-490300ccb957-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison between two cities'}, 'id': 'call_bs7q'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'temperature comparison between two cities'}, 'id': 'call_bs7q'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content=\"[{'url': 'https://www.bestplaces.net/climate/', 'content': '2024 Compare Climate & Weather. What city has the best weather year round? What city in the US has the best weather in summer? Our climate & weather tool can help. Compare two cities that interest you. We have todays weather, high temperature, low temperature, rainfall, precipitation, snow, sun, clouds, humidity, and wind. Enter First Place'}, {'url': 'https://weatherspark.com/compare', 'content': 'Weather Spark lets you compare and contrast the weather and climate between any two to four cities worldwide. You get a detailed report with graphs showing the precise differences between them. Even better than a side-by-side comparison, the report shows you the information in unified graphs. Please select a first city to compare'}]\", name='tavily_search_results_json', tool_call_id='call_bs7q')]}\n",
      "{'messages': [AIMessage(content='Please provide the two cities you would like to compare.', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1447, 'total_tokens': 1458, 'completion_time': 0.030744605, 'prompt_time': 0.28108085, 'queue_time': None, 'total_time': 0.311825455}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-05ef29a2-6c0b-4a9c-a3e1-63f0a0bcf00d-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_uO9bV3PNXOZiSRVWoNnzogsN'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| sunny| with| a| temperature| of| |57|.|0|°F| (|13|.|9|°C|).| The| wind| speed| is| |3|.|6| km|/h| coming| from| the| north|.| The| humidity| is| at| |83|%,| and| there| is| no| precipitation|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events(\n",
    "    {\"messages\": messages}, thread, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
